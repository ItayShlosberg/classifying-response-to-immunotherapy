{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from  os.path import join\n",
    "import sys\n",
    "import os\n",
    "lib = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\python_playground\\classifying-response-to-immunotherapy\\utilities\\droplet_dataset'\n",
    "lib2 = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\python_playground\\classifying-response-to-immunotherapy\\utilities'\n",
    "lib3 = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\python_playground\\classifying-response-to-immunotherapy\\data_analysis'\n",
    "lib4 = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\python_playground\\classifying-response-to-immunotherapy'\n",
    "lib5 = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\python_playground\\classifying-response-to-immunotherapy\\scripts'\n",
    "sys.path.append(lib)\n",
    "sys.path.append(lib2)\n",
    "sys.path.append(lib3)\n",
    "sys.path.append(lib4)\n",
    "sys.path.append(lib5)\n",
    "import os\n",
    "from os.path import join\n",
    "import sklearn\n",
    "# from droplet_dataset import *\n",
    "# from utilities import *\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib.pyplot import figure\n",
    "from termcolor import colored\n",
    "import tables\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\KerenYlab\\Desktop\\Technion studies\\Keren laboratory\\Data\\droplet_seq\\DEBUG\\1000_rand_cells.pkl'\n",
    "cohort = pickle.load(open(PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(self, test_size=0.2, shuffle=True, stratify=True):\n",
    "    \"\"\"\n",
    "    :param test_size: in proportion to the number of patients (not proportion to nubber of cells)\n",
    "    :param shuffle:\n",
    "    :param random_state:\n",
    "    :param stratify: Always, equal ration of responder to non-responder between test-set and train-set.\n",
    "    :return: x_train, x_test, and corresponding indexes\n",
    "    \"\"\"\n",
    "\n",
    "    responders = list(set([p.patient_details for p in self.cells_information_list if p.response_label]))\n",
    "    non_responders = list(set([p.patient_details for p in self.cells_information_list if not p.response_label]))\n",
    "    if shuffle:\n",
    "        random.shuffle(responders)\n",
    "        random.shuffle(non_responders)\n",
    "\n",
    "    train_responders = responders[:int(len(responders) * (1 - test_size))]\n",
    "    test_responders = responders[int(len(responders) * (1 - test_size)):]\n",
    "    train_non_responders = non_responders[:int(len(non_responders) * (1 - test_size))]\n",
    "    test_non_responders = non_responders[int(len(non_responders) * (1 - test_size)):]\n",
    "\n",
    "    train_patients = train_responders + train_non_responders\n",
    "    test_patients = test_responders + test_non_responders\n",
    "\n",
    "    train_idxs = [idx for idx, p in enumerate(self.cells_information_list['patient_details']) if p in train_patients]\n",
    "    test_idxs = [idx for idx, p in enumerate(self.cells_information_list['patient_details']) if p in test_patients]\n",
    "\n",
    "    x_train = self[train_idxs]\n",
    "    x_test = self[test_idxs]\n",
    "\n",
    "    return x_train, x_test, train_idxs, test_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M120', 'M103', 'M115', 'M129', 'M105', 'M122', 'M143', 'M106', 'M124', 'M126', 'M110', 'M118', 'M132', 'M136', 'M130', 'M145', 'M139', 'M134', 'M144', 'M116', 'M121', 'M127', 'M109', 'M100', 'M111', 'M97', 'M131', 'M138', 'M104', 'M112', 'M141', 'M133', 'M146', 'M123', 'M137', 'M108', 'M107', 'M140', 'M99', 'M101', 'M102', 'M135', 'M128', 'M98', 'M114']\n",
      "\n",
      "['M126', 'M123', 'M127', 'M139', 'M100', 'M107', 'M145', 'M111', 'M98', 'M121', 'M112', 'M115', 'M136', 'M114', 'M105', 'M144', 'M129', 'M133', 'M104', 'M135', 'M141', 'M137', 'M128', 'M130', 'M124', 'M131', 'M132', 'M102', 'M97', 'M110', 'M120', 'M99', 'M146', 'M140', 'M122', 'M143', 'M109', 'M134', 'M108', 'M106', 'M103', 'M116', 'M101', 'M138', 'M118']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "res = list(set(cohort.samples))\n",
    "print(res, end='\\n\\n')\n",
    "random.shuffle(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['M100', 16], ['M101', 17], ['M102', 69], ['M103', 8], ['M104', 20], ['M105', 31], ['M106', 19], ['M107', 32], ['M108', 8], ['M109', 33], ['M110', 14], ['M111', 31], ['M112', 17], ['M114', 44], ['M115', 17], ['M116', 12], ['M118', 5], ['M120', 21], ['M121', 25], ['M122', 12], ['M123', 16], ['M124', 25], ['M126', 16], ['M127', 16], ['M128', 39], ['M129', 11], ['M130', 21], ['M131', 22], ['M132', 25], ['M133', 14], ['M134', 5], ['M135', 14], ['M136', 18], ['M137', 31], ['M138', 17], ['M139', 19], ['M140', 16], ['M141', 10], ['M143', 53], ['M144', 38], ['M145', 32], ['M146', 34], ['M97', 18], ['M98', 16], ['M99', 23]]\n",
      "\n",
      "[['M99', 23], ['M124', 25], ['M112', 17], ['M122', 12], ['M115', 17], ['M128', 39], ['M104', 20], ['M108', 8], ['M103', 8], ['M140', 16], ['M109', 33], ['M130', 21], ['M141', 10], ['M136', 18], ['M144', 38], ['M138', 17], ['M145', 32], ['M120', 21], ['M123', 16], ['M100', 16], ['M111', 31], ['M114', 44], ['M107', 32], ['M101', 17], ['M126', 16], ['M146', 34], ['M143', 53], ['M116', 12], ['M110', 14], ['M135', 14], ['M127', 16], ['M137', 31], ['M106', 19], ['M105', 31], ['M139', 19], ['M102', 69], ['M134', 5], ['M131', 22], ['M98', 16], ['M121', 25], ['M133', 14], ['M129', 11], ['M118', 5], ['M97', 18], ['M132', 25]]\n",
      "\n",
      "[['M99', 23], ['M124', 48], ['M112', 65], ['M122', 77], ['M115', 94], ['M128', 133], ['M104', 153], ['M108', 161], ['M103', 169], ['M140', 185], ['M109', 218], ['M130', 239], ['M141', 249], ['M136', 267], ['M144', 305], ['M138', 322], ['M145', 354], ['M120', 375], ['M123', 391], ['M100', 407], ['M111', 438], ['M114', 482], ['M107', 514], ['M101', 531], ['M126', 547], ['M146', 581], ['M143', 634], ['M116', 646], ['M110', 660], ['M135', 674], ['M127', 690], ['M137', 721], ['M106', 740], ['M105', 771], ['M139', 790], ['M102', 859], ['M134', 864], ['M131', 886], ['M98', 902], ['M121', 927], ['M133', 941], ['M129', 952], ['M118', 957], ['M97', 975], ['M132', 1000]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dd = [list(ii) for ii in list(dict(Counter(cohort.samples)).items())]\n",
    "print(dd, end='\\n\\n')\n",
    "\n",
    "random.shuffle(dd)\n",
    "print(dd, end='\\n\\n')\n",
    "ee = dd\n",
    "for idx in range(1, len(ee)):\n",
    "    ee[idx][1] += ee[idx-1][1]\n",
    "print(ee, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = cohort.number_of_cells * 0.2\n",
    "number_of_cells_acc = np.array([ii[1] for ii in ee])\n",
    "samples_acc = np.array([ii[0] for ii in ee])\n",
    "\n",
    "\n",
    "# samples_acc[~(number_of_cells_acc < test_set_size)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(cohortq):\n",
    "    import random\n",
    "    res = list(set(cohort.samples))\n",
    "    print(res, end='\\n\\n')\n",
    "    random.shuffle(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(cohort.counts[0])[-100:]\n",
    "# test_size = 0.2\n",
    "# Counter(cohort.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TNMD'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort.gene_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M100'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort.samples[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
